{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08b286fc",
   "metadata": {},
   "source": [
    "# 1  Automated data cleaning for chest Xrays with cleanX: notebook for medical professionals with limited coding abililties. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae5502b",
   "metadata": {},
   "source": [
    "CleanX is a code library by Candace Makeda Moore, MD, Oleg Sivokon, and Andrew Murphy. Please note this workflow does not cover the whole scope of cleanX, and is only meant to show some of the functionality that can be accomplished using cleanX. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d5d511",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to educate people with very limited understanding of machine learning and code about some of what cleanX does, and why it is worth incorporating it into use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc91a399",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path = ['D:/projects/cleanX'] + sys.path\n",
    "# we will need to import some libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "from cleanX import (\n",
    "    dataset_processing as csvp,\n",
    "    dicom_processing as dicomp,\n",
    "    image_work as iwork,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19447588",
   "metadata": {},
   "source": [
    "Reading and analysis of chest X-rays is a common task in hospitals. In fact in many hospitals so many chest X-rays are performed that some are never read, and some are only read by people with limited training in radiology. Some countries have a very limited number of radiologists so radiographers read the chest X-rays. Regardless of who reads these images, they can be difficult to interpret and the error rate is reported as high in the medical literature (over 10% or even over 15% depending upon the source). Machine learning based algorithms have the potential to improve this situation in a variety of ways, however machine learning algorithms are powered by mountains of labeled data. And this need for labeled data creates a potential problem. \n",
    "\n",
    "Labeled data must either be retrieved from existing read X-rays (errors included), or created by humans (already over-burdened with reading X-rays, actually that was the original problem in the first place, right?). Several groups have created big datasets that algorithms can be trained on, but no dataset is perfect for every task. Unfortunately many datasets contain images that may not be appropriate to make a machine learning algorithm from. As a case in point, let's take a look at some of the data in a large set of COVID-19 images. We will use the CoronaHack -Chest X-Ray-Dataset from Kaggle. The dataset was assembled by Praveen Govindaraj. This dataset has thousands of images...too many to look through by hand without wasting a lot of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6167c55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_folder ='D:/my_academia/ncs/Coronahack-Chest-XRay-Dataset/Coronahack-Chest-XRay-Dataset/train/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cde95a",
   "metadata": {},
   "source": [
    "## Finding duplicates\n",
    "We may or may not want to use duplicated images to build an algorithm. Generally, it's a bad idea. At the extreme, if all of one pathology is simply duplicated images, we do not have enough data. Instead of trying to remember if we see duplicates in thousands of images, let's ask cleanX. cleanX compares the images pixel by pixel, and this takes time if you don't have a powerful computer, but it doesn't take human time. We can take a much needed break! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1355b4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "found = iwork.find_duplicated_images_todf(origin_folder)\n",
    "len(found[found.status == 'duplicated'])  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbe7af8",
   "metadata": {},
   "source": [
    "OK, so we may have 26 duplicates. Not so bad out of thousands of pictures. Let's pull up a list so we can check them by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca3ae86",
   "metadata": {},
   "outputs": [],
   "source": [
    "found[found.status == 'duplicated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8b6145",
   "metadata": {},
   "outputs": [],
   "source": [
    "wierd_images = found[found.status == 'duplicated']\n",
    "wierd_images_list = wierd_images.images.to_list()\n",
    "\n",
    "# we need the full file path\n",
    "final_names = []\n",
    "for image_string in wierd_images_list:\n",
    "    final_names.append(os.path.join(origin_folder, image_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeacf791",
   "metadata": {},
   "outputs": [],
   "source": [
    "iwork.show_images_in_df(final_names,19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f566db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a function that compares one image to list, and finds closest. \n",
    "import cv2\n",
    "import numpy as np\n",
    "image1 = 'person1372_bacteria_3502.jpeg'\n",
    "image1name = os.path.join(origin_folder, image1)\n",
    "compare_list = final_names\n",
    "image1image = cv2.imread(image1name)\n",
    "results = []\n",
    "pictures = []\n",
    "width, height = image1image.shape[1], image1image.shape[0]\n",
    "dim = (width, height)\n",
    "for picture in compare_list:\n",
    "    \n",
    "    image_there = cv2.imread(picture)\n",
    "    resized = cv2.resize(image_there, dim, interpolation = cv2.INTER_AREA)\n",
    "    result = resized - image1image\n",
    "    result_sum = np.sum(result)\n",
    "    results.append(result_sum)\n",
    "    pictures.append(pictures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a033c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'results':results,'pictures':pictures}\n",
    "ho = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1c012d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ho"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5ed07c",
   "metadata": {},
   "source": [
    "Interesting, some of our duplicated pictures appear to have been triplicated, and we get two of the same duplicate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7815ab",
   "metadata": {},
   "source": [
    "## Finding outlier images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061337bc",
   "metadata": {},
   "source": [
    "Now let's move on to seeing if we really have all similarly shot chest Xrays, or some nonsense flew in. We can use one of several methods with cleanX:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a376c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in a chest Xray we expect more white on top- the abdomen is bigger than the neck, let's see where that is not true\n",
    "upper_lower_returned = iwork.find_sample_upper_greater_than_lower(origin_folder, 10)\n",
    "# let's look at a sample of upper part of images and see if there are outliers\n",
    "upper_scan_returned = iwork.find_by_sample_upper(origin_folder, 10, 200)\n",
    "#let's compare each image to an average of all images, and take the most different\n",
    "tiny_image_different = iwork.find_tiny_image_differences(origin_folder, percentile=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99668676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os \n",
    "\n",
    "#import shutil\n",
    "from PIL import Image, ImageOps\n",
    "import math\n",
    "import filecmp\n",
    "import tesserocr\n",
    "from tesserocr import PyTessBaseAPI\n",
    "from filecmp import cmp\n",
    "from pathlib import Path\n",
    "import re\n",
    "import makedalytics as ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8e46cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get images and group by size\n",
    "target_upside_down= 'D:/my_academia/new_dicom_output'\n",
    "to_be_sorted = glob.glob(os.path.join(target_upside_down, '*.jpg'))\n",
    "pic_list = []\n",
    "heights = []\n",
    "widths = []\n",
    "dimension_groups = []\n",
    "# group = 0\n",
    "for picy in to_be_sorted:\n",
    "    \n",
    "    example = cv2.imread(picy, cv2.IMREAD_GRAYSCALE)\n",
    "    height = example.shape[0]\n",
    "    width = example.shape[1]\n",
    "    height_width= 'h'+str(height) + '_w' + str(width)\n",
    "    heights.append(height)    \n",
    "    widths.append(width)\n",
    "    pic_list.append(picy)\n",
    "    dimension_groups.append(height_width) \n",
    "    #if height, width == height, width\n",
    "    #group += 1\n",
    "    d = {'pics' : pic_list, 'height': heights, 'width': widths, 'height_width':dimension_groups}\n",
    "    data = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d52e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74257bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted_f = pd.DataFrame(data.groupby(data.height_width))\n",
    "# sorted_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6c1c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sort_values('height_width')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e136d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict_of_dfs = {f'data{i}':data[['pics','height','width', i]] for i in data.columns[3:]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d3aa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.columns[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21711e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict_of_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f98eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "compuniquesizes = data.height_width.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96c55e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizesdict = {elem : pd.DataFrame() for elem in compuniquesizes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313d370e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in sizesdict.keys():\n",
    "    sizesdict[key] = data[:][data.height_width == key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1add9921",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizesdict['h704_w1194']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4644b6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "compuniquesizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880b7b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "compuniquesizes, sizesdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71b8274",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sized in compuniquesizes:\n",
    "    print(sized)\n",
    "    print(len(sizesdict[sized]))\n",
    "    print(sizesdict[sized])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e48f7d77",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'compuniquesizes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1424/2145497451.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlen_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msize_name_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0msized\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcompuniquesizes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mlener\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msizesdict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msized\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mlen_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'compuniquesizes' is not defined"
     ]
    }
   ],
   "source": [
    "len_list = []\n",
    "size_name_list = []\n",
    "for sized in compuniquesizes:\n",
    "    lener= len(sizesdict[sized])\n",
    "    len_list.append(lener)\n",
    "    size_name_list.append(sized)\n",
    "sized_data = {'size':size_name_list, 'count':len_list}\n",
    "df = pd.DataFrame(sized_data)\n",
    "    #print(len(sizesdict[sized]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf70924",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42f2347e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_me_size_count_df(folder):\n",
    "    \"\"\"\n",
    "    This function returns a dataframe of unique sized, and how many pictures \n",
    "    have such a size.\n",
    "    :param folder: folder with jpgs\n",
    "    :type folder: string\n",
    "\n",
    "    :return: df\n",
    "    :rtype: pandas.core.frame.DataFrame\n",
    "    \"\"\"\n",
    "    to_be_sorted = glob.glob(os.path.join(folder, '*.jpg'))\n",
    "    pic_list = []\n",
    "    heights = []\n",
    "    widths = []\n",
    "    dimension_groups = []\n",
    "    for picy in to_be_sorted:\n",
    "        example = cv2.imread(picy, cv2.IMREAD_GRAYSCALE)\n",
    "        height = example.shape[0]\n",
    "        width = example.shape[1]\n",
    "        height_width= 'h'+str(height) + '_w' + str(width)\n",
    "        heights.append(height)    \n",
    "        widths.append(width)\n",
    "        pic_list.append(picy)\n",
    "        dimension_groups.append(height_width) \n",
    "        d = {'pics' : pic_list, 'height': heights, 'width': widths, 'height_width':dimension_groups}\n",
    "        data = pd.DataFrame(d)\n",
    "        data = data.sort_values('height_width')\n",
    "        compuniquesizes = data.height_width.unique()\n",
    "        len_list = []\n",
    "    size_name_list = []\n",
    "    sizesdict = {elem : pd.DataFrame() for elem in compuniquesizes}\n",
    "    for key in sizesdict.keys():\n",
    "        sizesdict[key] = data[:][data.height_width == key]\n",
    "    for sized in compuniquesizes:\n",
    "        lener= len(sizesdict[sized])\n",
    "        len_list.append(lener)\n",
    "        size_name_list.append(sized)\n",
    "    sized_data = {'size':size_name_list, 'count':len_list}\n",
    "    df = pd.DataFrame(sized_data)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e28dc4ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         size  count\n",
      "0   h128_w128      2\n",
      "1   h256_w256      3\n",
      "2   h576_w448      4\n",
      "3   h576_w576      2\n",
      "4  h704_w1194      1\n"
     ]
    }
   ],
   "source": [
    "target_upside_down= 'D:/my_academia/new_dicom_output'\n",
    "print(give_me_size_count_list(target_upside_down))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "15acf257",
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_me_size_counted_dfs(folder):\n",
    "    \"\"\"\n",
    "    This function returns dataframes of unique sized \n",
    "    :param folder: folder with jpgs\n",
    "    :type folder: string\n",
    "\n",
    "    :return: big_sizer\n",
    "    :rtype: list\n",
    "    \"\"\"\n",
    "    to_be_sorted = glob.glob(os.path.join(folder, '*.jpg'))\n",
    "    pic_list = []\n",
    "    heights = []\n",
    "    widths = []\n",
    "    dimension_groups = []\n",
    "    for picy in to_be_sorted:\n",
    "        example = cv2.imread(picy, cv2.IMREAD_GRAYSCALE)\n",
    "        height = example.shape[0]\n",
    "        width = example.shape[1]\n",
    "        height_width= 'h'+str(height) + '_w' + str(width)\n",
    "        heights.append(height)    \n",
    "        widths.append(width)\n",
    "        pic_list.append(picy)\n",
    "        dimension_groups.append(height_width) \n",
    "        d = {'pics' : pic_list, 'height': heights, 'width': widths, 'height_width':dimension_groups}\n",
    "        data = pd.DataFrame(d)\n",
    "        data = data.sort_values('height_width')\n",
    "        compuniquesizes = data.height_width.unique()\n",
    "        len_list = []\n",
    "    size_name_list = []\n",
    "    sizesdict = {elem : pd.DataFrame() for elem in compuniquesizes}\n",
    "    for key in sizesdict.keys():\n",
    "        sizesdict[key] = data[:][data.height_width == key]\n",
    "    big_sizer = []\n",
    "    for nami in compuniquesizes:\n",
    "        frames = sizesdict[nami]\n",
    "        big_sizer.append(frames)\n",
    "    return big_sizer    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2f688d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(give_me_size_counted_dfs('D:/my_academia/new_dicom_output')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d49080",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
